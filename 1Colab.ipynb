{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 1挂载云盘\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 2安装依赖\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# Workaround from: https://github.com/m-bain/whisperX/issues/1027#issuecomment-2627525081\n",
    "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "\n",
    "!pip install ctranslate2==4.4.0\n",
    "!pip install faster-whisper==1.1.1\n",
    "!pip install pysrt\n",
    "!pip install pyannote.audio\n",
    "!pip install imageio-ffmpeg\n",
    "!pip install \"audio-separator[gpu]\"\n",
    "\n",
    "\n",
    "\n",
    "!apt-get update\n",
    "!apt-get install libcudnn8=8.9.2.26-1+cuda12.1\n",
    "!apt-get install libcudnn8-dev=8.9.2.26-1+cuda12.1\n",
    "!pip install pyannote.audio\n",
    "\n",
    "!python -c \"import torch; torch.backends.cuda.matmul.allow_tf32 = True; torch.backends.cudnn.allow_tf32 = True\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 3导入配置\n",
    "import os\n",
    "config = {\n",
    "    \"pre_path\": \"a_pre\",\n",
    "    \"work_path\": \"b_work\",\n",
    "    \"asr_path\": \"c_asr\",\n",
    "    \"tsl_path\": \"d_tsl\",\n",
    "    \"model_path\": \"z_model\",\n",
    "    \"log_path\": \"z_log\",\n",
    "    \"separator\": \"MDX23C-8KFFT-InstVoc_HQ_2.ckpt\",\n",
    "    \"vad\": \"4evergr8/pyannote-segmentation-3.0\",\n",
    "    \"asr\": \"large-v3\",\n",
    "    \"translate\": \"gemini-1.5-flash\",\n",
    "    \"batch_size\": 8,\n",
    "    \"min_duration_on\": 0.0,\n",
    "    \"min_duration_off\": 0.2,\n",
    "    \"space\": 2,\n",
    "    \"language\": \"ja\",\n",
    "    \"num_workers\": 1,\n",
    "    \"api_key\": \"\",\n",
    "    \"prompt\": \"\"\"你是一名专业的翻译家，请你按照以下流程进行翻译：\n",
    "第一步：初步直译\n",
    "将日语文本逐行直译成简体中文文本，保留序号、标记符、占位符、换行符等特殊内容，保持原来的格式。\n",
    "\n",
    "第二步：深入校正\n",
    "针对每一句初步译文，可以从语义与语境、专业术语、上下文信息、翻译风格、故事背景、人物设定等等方面出发，进行深入分析和校正。\n",
    "\n",
    "第三步：最终意译与润色\n",
    "整合直译结果和校正建议，进行最终的意译和润色，生成自然流畅、符合简体中文表达习惯的最终译文。\n",
    "\n",
    "### 翻译原则\n",
    "忠实准确地进行翻译。原作是伟大艺术作品，允许使用直白或粗俗的描述，不应随意删减或篡改，不应回避或淡化，以保持作品的原貌。\n",
    "只输出最终的翻译结果，不输出中间结果，结合上下文进行翻译，注意用“|”分割的序号，我会先将原文发给你用来熟悉上下文，然后分批次获取翻译内容，原文如下：\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def get_path(config_value):\n",
    "    path = os.path.join('/content/gdrive/MyDrive/ASMRASR', config_value)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    print(f\"创建文件夹: {path}\")\n",
    "    return path\n",
    "\n",
    "config[\"pre_path\"] = get_path(config[\"pre_path\"])\n",
    "config[\"work_path\"] = get_path(config[\"work_path\"])\n",
    "config[\"asr_path\"] = get_path(config[\"asr_path\"])\n",
    "config[\"tsl_path\"] = get_path(config[\"tsl_path\"])\n",
    "config[\"model_path\"] = get_path(config[\"model_path\"])\n",
    "config[\"log_path\"] = get_path(config[\"log_path\"])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 4音频切分\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from imageio_ffmpeg import get_ffmpeg_exe\n",
    "from audio_separator.separator import Separator\n",
    "\n",
    "ffmpeg = get_ffmpeg_exe()\n",
    "os.system(\"chcp 65001\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(config[\"pre_path\"]):\n",
    "    for filename in files:\n",
    "        if filename.endswith((\".wav\", \".mp3\", \".flac\")):\n",
    "            audio_path = os.path.join(root, filename)\n",
    "\n",
    "            if os.path.exists(os.path.join(config[\"pre_path\"], \"slice\")):\n",
    "                shutil.rmtree(os.path.join(config[\"pre_path\"], \"slice\"))  # 删除原文件夹及其内容\n",
    "            os.makedirs(os.path.join(config[\"pre_path\"], \"slice\"))  # 创建新文件夹\n",
    "\n",
    "            segment_length = 180  # 20 分钟 = 1200 秒\n",
    "            command = [\n",
    "                \"ffmpeg\", \"-i\", audio_path,  # 输入音频文件\n",
    "                \"-f\", \"segment\",  # 使用 segment 格式进行切割\n",
    "                \"-segment_time\", str(segment_length),  # 设置每段的时长（单位：秒）\n",
    "                \"-c\", \"copy\",  # 保持原始编码（无损切割）\n",
    "                os.path.join(os.path.join(config[\"pre_path\"], \"slice\"), \"%03d.wav\")  # 输出文件的命名格式\n",
    "            ]\n",
    "            subprocess.run(command)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 5人声分离\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from imageio_ffmpeg import get_ffmpeg_exe\n",
    "from audio_separator.separator import Separator\n",
    "\n",
    "ffmpeg = get_ffmpeg_exe()\n",
    "os.system(\"chcp 65001\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(config[\"pre_path\"]):\n",
    "    for filename in files:\n",
    "        if filename.endswith((\".wav\", \".mp3\", \".flac\")):\n",
    "            audio_path = os.path.join(root, filename)\n",
    "\n",
    "\n",
    "            if os.path.exists(os.path.join(config[\"pre_path\"], \"split\")):\n",
    "                shutil.rmtree(os.path.join(config[\"pre_path\"], \"split\"))  # 删除原文件夹及其内容\n",
    "            os.makedirs(os.path.join(config[\"pre_path\"], \"split\"))  # 创建新文件夹\n",
    "            separator = Separator(\n",
    "                model_file_dir=config[\"model_path\"],\n",
    "                output_dir=os.path.join(config[\"pre_path\"],'split'),\n",
    "                output_single_stem=\"vocals\",\n",
    "                sample_rate=16000\n",
    "            )\n",
    "            separator.load_model(model_filename=config[\"separator\"])\n",
    "            output_files = separator.separate(os.path.join(config[\"pre_path\"], \"slice\"))\n",
    "            print(\"output_files\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 6音频合并\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from imageio_ffmpeg import get_ffmpeg_exe\n",
    "from audio_separator.separator import Separator\n",
    "\n",
    "ffmpeg = get_ffmpeg_exe()\n",
    "os.system(\"chcp 65001\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(config[\"pre_path\"]):\n",
    "    for filename in files:\n",
    "        if filename.endswith((\".wav\", \".mp3\", \".flac\")):\n",
    "            audio_path = os.path.join(root, filename)\n",
    "\n",
    "            file_list = sorted(\n",
    "                [f for f in os.listdir(os.path.join(config[\"pre_path\"],'split')) if f.endswith(\".wav\")],\n",
    "                key=lambda x: int(x[:3])\n",
    "            )\n",
    "            concat_input = \"|\".join([os.path.join(os.path.join(config[\"pre_path\"],'split'), f) for f in file_list])\n",
    "\n",
    "            basename = os.path.splitext(filename)[0]\n",
    "            output_path = os.path.join(config[\"work_path\"], f\"{basename}.wav\")\n",
    "\n",
    "            command = [\n",
    "                \"ffmpeg\",\n",
    "                \"-i\", f\"concat:{concat_input}\",\n",
    "                \"-c\", \"copy\",\n",
    "                output_path\n",
    "            ]\n",
    "\n",
    "            subprocess.run(command)\n",
    "            print(f\"合并完成：{output_path}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 7音频转写\n",
    "import gc\n",
    "import pysrt\n",
    "import torch\n",
    "import numpy as np\n",
    "from pyannote.audio import Model\n",
    "from faster_whisper import WhisperModel\n",
    "import librosa\n",
    "from pyannote.audio.pipelines import VoiceActivityDetection\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "\n",
    "# 数据结构\n",
    "@dataclass\n",
    "class AudioSegmentInfo:\n",
    "    start: float\n",
    "    end: float\n",
    "    group_start: float\n",
    "    group_end: float\n",
    "    text: str = \"...\"\n",
    "\n",
    "@dataclass\n",
    "class AudioData:\n",
    "    audio_array: np.ndarray\n",
    "    segment_info_list: list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 硬件\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "print('设备:', device, '类型:', compute_type)\n",
    "\n",
    "# 只初始化一次ASR模型（不会在每个音频内循环初始化）\n",
    "\n",
    "\n",
    "# 遍历所有音频\n",
    "for root, dirs, files in os.walk(config[\"work_path\"]):\n",
    "    for filename in files:\n",
    "        audio_path = os.path.join(root, filename)\n",
    "        basename = os.path.splitext(filename)[0]\n",
    "        print(f\"\\n处理音频: {audio_path}\")\n",
    "\n",
    "        # Step 1: 加载音频\n",
    "        audio, sr = librosa.load(str(audio_path), sr=16000, mono=True)\n",
    "\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        vad_model = Model.from_pretrained(checkpoint=config[\"vad\"], cache_dir=config[\"model_path\"])\n",
    "        vad_model.to(torch.device(device))\n",
    "        vad_pipeline = VoiceActivityDetection(segmentation=vad_model)\n",
    "        vad_pipeline.instantiate({\n",
    "            \"min_duration_on\": config[\"min_duration_on\"],\n",
    "            \"min_duration_off\": config[\"min_duration_off\"],\n",
    "        })\n",
    "\n",
    "        vad_result = vad_pipeline(str(audio_path))\n",
    "\n",
    "        # VAD结束，释放模型和缓存\n",
    "        del vad_pipeline, vad_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Step 3: 切人声片段\n",
    "        timeline = vad_result.get_timeline()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        audio_groups = []\n",
    "        group_start_limit = 30 * 60  # 每组音频的时间限制，30分钟\n",
    "\n",
    "        silence = np.zeros(int(sr * config[\"space\"]), dtype=audio.dtype)\n",
    "\n",
    "        audio_groups = []\n",
    "        group_start_limit = 30 * 60  # 每组音频的时间限制，30分钟\n",
    "        silence_duration = config[\"space\"]\n",
    "        silence = np.zeros(int(sr * silence_duration), dtype=audio.dtype)\n",
    "\n",
    "        for segment in timeline:\n",
    "            # 计算当前 segment 的时间\n",
    "            segment_start = segment.start\n",
    "            segment_end = segment.end\n",
    "\n",
    "            # 所属分组\n",
    "            group_index = int(segment_end // group_start_limit)\n",
    "\n",
    "            # 创建新分组（如果尚不存在）\n",
    "            while len(audio_groups) <= group_index:\n",
    "                audio_groups.append(AudioData(audio_array=np.array([]), segment_info_list=[]))\n",
    "\n",
    "            # 添加 segment_info 到对应组\n",
    "            audio_groups[group_index].segment_info_list.append(\n",
    "                AudioSegmentInfo(start=segment_start, end=segment_end, group_start=0.0, group_end=0.0)\n",
    "            )\n",
    "\n",
    "        # 对每组音频进行拼接处理\n",
    "        for audio_group in audio_groups:\n",
    "            group_audio = []\n",
    "            current_group_end = 0.0\n",
    "\n",
    "            for i, segment in enumerate(audio_group.segment_info_list):\n",
    "                segment_start = segment.start\n",
    "                segment_end = segment.end\n",
    "\n",
    "                # 计算拼接后的位置\n",
    "                group_start = current_group_end\n",
    "                group_end = group_start + (segment_end - segment_start)\n",
    "\n",
    "                # 更新 group_start 和 group_end\n",
    "                segment.group_start = group_start\n",
    "                segment.group_end = group_end\n",
    "\n",
    "                # 提取音频段\n",
    "                start_sample = int(segment_start * sr)\n",
    "                end_sample = int(segment_end * sr)\n",
    "                audio_seg = audio[start_sample:end_sample]\n",
    "\n",
    "                # 加入静音（除首段）\n",
    "                if i > 0:\n",
    "                    group_audio.append(silence)\n",
    "                group_audio.append(audio_seg)\n",
    "\n",
    "                # 更新下一段的起点\n",
    "                current_group_end = group_end + (\n",
    "                    silence_duration if i < len(audio_group.segment_info_list) - 1 else 0)\n",
    "\n",
    "            if group_audio:\n",
    "                audio_group.audio_array = np.concatenate(group_audio)\n",
    "            else:\n",
    "                audio_group.audio_array = np.array([])\n",
    "\n",
    "        del audio\n",
    "        subs = pysrt.SubRipFile()\n",
    "        for audio_group in audio_groups:\n",
    "            for segment in audio_group.segment_info_list:\n",
    "                sub = pysrt.SubRipItem(\n",
    "                    index=len(subs) + 1,  # 字幕索引\n",
    "                    start=pysrt.SubRipTime.from_ordinal(int(segment.group_start * 1000)),  # 转换 start 为 SRT 时间格式\n",
    "                    end=pysrt.SubRipTime.from_ordinal(int(segment.group_end * 1000)),  # 转换 end 为 SRT 时间格式\n",
    "                    text=segment.text  # 字幕内容\n",
    "                )\n",
    "                subs.append(sub)\n",
    "\n",
    "\n",
    "        srt_path = os.path.join(config[\"log_path\"], f\"before-{basename}.srt\")\n",
    "        subs.save(srt_path)\n",
    "        print(f\"log写入: {srt_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        gc.collect()\n",
    "        asr_model = WhisperModel(\n",
    "            config[\"asr\"],\n",
    "            device=device,\n",
    "            compute_type=compute_type,\n",
    "            download_root=config[\"model_path\"],\n",
    "            num_workers=20\n",
    "        )\n",
    "        subs = pysrt.SubRipFile()\n",
    "        for audio_group in audio_groups:\n",
    "            segments, _ = asr_model.transcribe(\n",
    "                audio=audio_group.audio_array,\n",
    "                beam_size=2,\n",
    "                vad_filter=False,\n",
    "                initial_prompt=basename,\n",
    "                language=config['language']\n",
    "            )\n",
    "\n",
    "            for seg in segments:\n",
    "                seg_start = seg.start\n",
    "                seg_end = seg.end\n",
    "                seg_text = seg.text.strip()\n",
    "\n",
    "                best_match = None\n",
    "                max_overlap = 0.0\n",
    "\n",
    "                subtitle = pysrt.SubRipItem(\n",
    "                    index=len(subs) + 1,\n",
    "                    start=pysrt.SubRipTime.from_ordinal(int(seg_start * 1000)),  # 转换为毫秒\n",
    "                    end=pysrt.SubRipTime.from_ordinal(int(seg_end * 1000)),  # 转换为毫秒\n",
    "                    text=seg_text\n",
    "                )\n",
    "                subs.append(subtitle)\n",
    "\n",
    "                for segment_info in audio_group.segment_info_list:\n",
    "                    # 求开始时间的最大值和结束时间的最小值\n",
    "                    overlap_start = max(seg_start, segment_info.group_start)\n",
    "                    overlap_end = min(seg_end, segment_info.group_end)\n",
    "\n",
    "                    # 如果重合时间大于零，计算重合时长\n",
    "                    overlap_duration = max(0.0, overlap_end - overlap_start)\n",
    "\n",
    "                    # 只有当重合时长大于零时，才可能是一个有效的匹配\n",
    "                    if overlap_duration >= max_overlap:\n",
    "                        max_overlap = overlap_duration\n",
    "                        best_match = segment_info\n",
    "\n",
    "                if best_match and max_overlap > 0:\n",
    "                    best_match.text = seg_text\n",
    "\n",
    "        srt_path = os.path.join(config[\"log_path\"], f\"asr-{basename}.srt\")\n",
    "        subs.save(srt_path)\n",
    "\n",
    "\n",
    "        del asr_model\n",
    "        gc.collect()\n",
    "        subs = pysrt.SubRipFile()\n",
    "\n",
    "        for audio_group in audio_groups:\n",
    "            # 创建 SRT 字幕文件对象\n",
    "\n",
    "\n",
    "            for segment in audio_group.segment_info_list:\n",
    "                # 将每个 segment 信息转换为 SRT 格式\n",
    "                sub = pysrt.SubRipItem(\n",
    "                    index=len(subs) + 1,  # 字幕索引\n",
    "                    start=pysrt.SubRipTime.from_ordinal(int(segment.start * 1000)),  # 转换 start 为 SRT 时间格式\n",
    "                    end=pysrt.SubRipTime.from_ordinal(int(segment.end * 1000)),  # 转换 end 为 SRT 时间格式\n",
    "                    text=segment.text  # 字幕内容\n",
    "                )\n",
    "                subs.append(sub)\n",
    "\n",
    "            # 设置输出 SRT 文件路径\n",
    "\n",
    "        srt_path = os.path.join(config[\"asr_path\"], f\"{basename}.srt\")\n",
    "\n",
    "\n",
    "        subs.save(srt_path)\n",
    "        print(f\"字幕写入: {srt_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title 8结果翻译\n",
    "import os\n",
    "import time\n",
    "import pysrt\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(config[\"asr_path\"]):\n",
    "    for filename in files:\n",
    "        if filename.endswith((\".srt\")):\n",
    "\n",
    "\n",
    "\n",
    "            srt_path = os.path.join(root, filename)\n",
    "            subs = pysrt.open(srt_path, encoding='utf-8')\n",
    "\n",
    "            for i in range(0, len(subs), 100):\n",
    "                chunk = subs[i:i + 100]\n",
    "\n",
    "                client = genai.Client(api_key=config[\"api_key\"])\n",
    "                chat = client.chats.create(\n",
    "                    model=config['translate'],\n",
    "                    config=types.GenerateContentConfig(\n",
    "                        system_instruction=config[\"prompt\"] + \"\\n\" + \"\\n\".join(sub.text for sub in chunk),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for j in range(0, len(chunk), 10):\n",
    "                    sub_chunk = chunk[j:j + 10]\n",
    "                    prompt = \"\\n\".join(f\"{k + 1}|{sub.text}\" for k, sub in enumerate(sub_chunk))\n",
    "\n",
    "                    while True:\n",
    "                        try:\n",
    "                            #print(prompt)\n",
    "                            response = chat.send_message(prompt)\n",
    "                            #print(response.text)\n",
    "                            lines = response.text.strip().splitlines()\n",
    "                            valid_lines = [line for line in lines if \"|\" in line]\n",
    "\n",
    "                            if len(valid_lines) == len(sub_chunk):\n",
    "                                for k, line in enumerate(valid_lines):\n",
    "                                    parts = line.split(\"|\", 1)\n",
    "                                    if len(parts) == 2:\n",
    "                                        sub_chunk[k].text = parts[1].strip()\n",
    "                                time.sleep(3)  # 成功后稍微等待\n",
    "                                break\n",
    "                            else:\n",
    "                                print(\"返回行数与原始字幕不一致，等待重试...\")\n",
    "                                time.sleep(2)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"异常：{e}\")\n",
    "                            time.sleep(3)\n",
    "\n",
    "            srt_path = os.path.join(config['tsl_path'], filename)\n",
    "            subs.save(srt_path, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#6翻译字幕"
   ],
   "metadata": {
    "id": "-fRcCEiH2chU"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XUCYF8sjWo7z",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "#@title 清理内存\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
